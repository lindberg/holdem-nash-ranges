# Regret-based system to reach Nash equilibrium  
A regret-based system is a way for a system to learn the appropriate action in a given situation based on the amount of regret that was given the last time the system chose the same action in the same or a similar situation. This is similar to how humans attain intuition.

Our initial task is to create a regret-based system that attempts to reach Nash equilibrium for push/fold heads-up no-limit hold’em when the effective stack is 10 big blinds. To do this we need two things:

* A regret-based system that over millions of hands learns the decision with most expected value in any given situation.
* A hand evaluator so the system knows which player won every specific hand.

We will check our results against other Nash equilibrium charts generated by different sources.

## Hand evaluator
With TwoPlusTwo hand evaluator, we can evaluate the strength of 7 given cards. The strength is represented as a number. When the number is higher, the hand is better. By comparing this number with the number strength of another 7 cards, we know which hand won.
Every card is represented by an integer 1-52:

![card table](img/table.png)

*Note: The order of the suits does not matter as long as it is consistent.*

## Regret-based system
For this we need:

* A way to store a regret tree.
* A way of cycling through millions of hands trying all possible different actions for every hand and updating the regret system accordingly.

### Regret tree
![regret tree](img/tree.png)

*Figure 1: A very simplified version of the regret tree only considering three different starting hands.*

In Figure 1 we can see how the regret tree is built in a simplified way. The actual regret tree looks the same but have 169 nodes for the small blind and 169 nodes for the big blind since there are 169 different starting hands in Texas Hold ‘em. This means that the actual regret tree consists of 169 * 2 = 338 regret nodes.

Note: There are actually 1 326 combinations of possible starting hands, but only 169 matter since for example Tc9c from a preflop perspective can be viewed the same as Th9h, so we group these and the two other suits of tens and nines and call them T9s.

Note 2: We don't give fold any regret since the expected value of folding will always be zero. What about losing blinds? The situation is analyzed after the blinds are placed. If we placed the blinds or if there are random blinds in the pot out of nowhere does not matter for out analysis of regret. Obviously the blinds do matter, but how they got to the pot does not.

Note 3: The information put in the tree could be better visualized with a table, but we use a tree since that is what would be used for a more complex problem.

We need a way to accurately give regret based on the result of an action. We can not just give +1 or -1 regret if the action turned out good or bad since the small blind and the big blind get different amounts of profit and loss if push or call works out or not. Therefore, we give regret in amount of profit or loss in small blinds that the action resulted in. A positive profit means a positive regret and a loss means a negative regret.

### Storage issues
In this particular case with only 338 regret nodes, we don't have to worry about storage or memory issues. However, if we want to make a more complicated system this might be an issue. If we used only one byte as a regret node, we would have a regret value ranging from -128 to 127. One successful push from the small blind would increase the regret value with 21 since 19 small blinds were used for the push and 40 small blinds were won, therefore a profit of 21 small blinds. Already, we would have used up more than 16 % of the limit of positive regret. This could create problems with variance since we are simulating millions of hands and the regret caps before the system can come to a valid conclusion of what the right action is in the specific spot.

Instead, if we use two bytes as the size for a regret node, one successful push would use up more than 0.06 % of the limit of positive regret. This might work for this problem, since it takes 1561 successful pushes to cap the regret node and it seems intuitively unreasonable that variance could bring this to below zero again after it is capped. For larger problems than this, with for example 200 small blinds in play, only 163 successful pushes from the small blind are needed to cap the regret node. This is a significantly different number than 1 561. We see that higher stack sizes require more regret node storage in order for the system to perform as good.

With all of that said, for this simple problem we use 4 bytes to really make sure that variance will never be a problem. In total, the regret file takes up 1 352 bytes of space.

### File structure
The program generates a regret.dat file if one does not already exist. We dedicate half of the file for the small blind and half of the file for the big blind. More specifically, the first 676 bytes are dedicated to the small blind and the following 676 bytes are dedicated to the big blind. The order of hands start with all the pairs 22-AA, then cycles through all the offsuited combinations 32o-A2o, 43o-A3o, …, KQo-AQo, AKo and finally cycle through the suited combinations in the same way.

![preflop hands](img/preflop_hands.png)

*Figure 2: Table of all starting hands (image source: PokerStove).*

This file is loaded into a vector of 4-byte integers and it is important we know how to correctly navigate through this vector.

If we for example want to find the regret for the big blind folding to T5s we take the following steps:
1. Skip forward half the nodes (169).
2. Skip forward all the pairs (13).
3. Skip forward all the offsuited combination nodes (78).
4. Skip forward all the suited combinations before T5s (37).
5. We have arrived at the node we are searching for.

Adding these numbers up, we conclude that we need to skip the first 297 elements in the vector. Since the first index is zero this would mean that our node is at index 297. The process of finding the right index is done by RegretTree’s RegretIndex function.

## Regret system
We said earlier that only 169 hands matter for this problem. In actuality, we needed to make sure that we did not match for example the same T9s against the same 56o every time, since there are three possible matchups here:
* 56o does not share any suit with T9s.
* The five in 56o is the same suit as T9s.
* The six in 56o is the same suit as T9s.

These three matchups will play slightly different against each other. An easy way to solve this is to pick completely random cards from a deck and converting them to one of the 169 hands afterwards and this is what the program does.
